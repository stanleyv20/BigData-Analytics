{\rtf1\ansi\ansicpg1252\cocoartf2634
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\margl1440\margr1440\vieww20160\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Steps to run project end to end\
1. Start the ZooKeeper service - $bin/zookeeper-server-start.sh config/zookeeper.properties\
2. Start Kafka broker service - $ bin/kafka-server-start.sh config/server.properties\
3.. Run TweetStreamer.py - this sends tweets relating to keyword \'93Elon\'94 via tweepy API to Kafka topic: ElonTweets\
4. Run PySpark_SentimentaAnalysis via PySpark - pulls from Kafka and write sentiment to kafka\
    -I ran this code locally with  Spark version 3.2.0 using Scala version 2.12.15.\
   - I start python via terminal with the following command: 
\f1\fs22 \cf2 \CocoaLigature0 pyspark --master local --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.3\
  - This is needed to provide argument of needed package for kafka streaming and to indicate to run locally without parallelism
\f0\fs24 \cf0 \CocoaLigature1 \
    - Environmental variables specified in my bash_profile for run:\
      
\f1\fs22 \cf2 \CocoaLigature0 export SPARK_HOME=/Users/Stanley/spark-3.0.3-bin-hadoop2.7\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
   export JAVA_HOME=$(/usr/libexec/java_home)\
   export PYTHONPATH=$\{SPARK_HOME\}/python:$PYTHONPATH\
   export PYTHONPATH=$\{SPARK_HOME\}/python/lib/py4j-0.10.9-src.zip:$PYTHONPATH\
   export PYSPARK_PYTHON=/usr/bin/python3\
   export PYSPARK_DRIVER_PYTHON=jupyter\
   export PYSPARK_DRIVER_PYTHON_OPTS=notebook\
   PATH=$PATH:$SPARK_HOME/bin\
\
  -Specified environmental variables to run program in Jupiter notebook rather than executing code using spark-submit in terminal   \
5. Run ELK Stack in separate terminals\
	1) Start elasticsearch \
    2) Start kibana\
    3. Start logstash with updated logstash.conf file : bin/logstash -f [Path to logstash.conf]\
\
   Contents of my logstash.conf file:\
input \{\
   kafka \{\
      bootstrap_servers => "localhost:9092"\
      topics => ["ElonSentiment"] \
   \}\
\}\
\
output \{\
   elasticsearch \{\
      hosts => "localhost"\
      index => "sentiment"\
   \}\
   stdout \{\}\
\}\
6. Visualization can be viewed and configured by navigating to http://localhost:5601 when ELK stack is running successfully\
\
}